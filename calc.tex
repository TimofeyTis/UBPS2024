
\section{Описание работы? программного комплекса}
Для исследования представленных в работе моделей были проведены серии вычислительных экспериментов. Эксперименты проводились на ПК с процессором Intel Core i7-10510U CPU@1.80ГГц и оперативной памятью объемом 8ГБ.

Опишем подробнее процесс подсчета политики управления $\hat{\pi}(a| s),$ опираясь на структурную схему.
Модуль адаптивного управления светофорными объектами загружает управляющий конфигурационный файл trafficLightConfig.xml. В конфигурационном файле содержится информация о возможных направлениях движения, количестве фаз и циклах светофорных объектов.
Далее  комплекс программных средств MARLIN24  связывает  показания  датчика в имитационном модуле  и рассчитывает оптимальное управление для светофорных объектов.

Пусть оптические датчики (VEHICLE DETECTOR) в имитационной среде (SIMULATION)  записывают момент появления $t_i$ пронумерованного транспортного средства $i \in I \subset \mathbb{N}$ в  зоне $z\in Zones  = \left\{z^{(0)}, z^{(1)}, \dots, z^{(m)} \right\}, m \in \mathbb{N}$.
Отметим, что при имитационном моделировании   псевдослучайная интенсивность движения транспортных средств будет задана алгоритмически. Это означает, что мы можем сконструировать множество пар $(i,z),$ что  автомобиль $i$ находится в детектируемой зоне $z$ в момент времени $t.$ Определим данное множество как отношение $\psi_t \subset \mathbb{N} \times Zones, $ для которого  $i\psi_t z.$
Введем также отношение $\phi \subset Zones \times \state,$ описывающее зоны $z, $ в которых состояние $s'$ разрешает движение.
Сгруппируем автомобили в  зонах в соответствии с фазой светофорного объекта $s'$, которая разрешает движение транспортных средств в этих зонах и обозначим
$
  I(s',t) = \left\{i|\;\; t_i < t, i \psi_t z, z \phi s' \right\}.
$

Приведем рассуждения, исходя из которых считается функция вознаграждения.
Для каждой полосы определено число машин  на отрезке дороги, начинающемся с детектора и заканчивающемся стоп-линией перекрестка.
Пусть  $r:  \state \times \action \mapsto \mathbb{R}$ --- функция вознаграждения агента при изменении наблюдаемого состояния $s_t$ при действии $a_t=\delta(s)$. 
В момент времени $t$ значение функции $r(s_t, a_t)=R_t$  определяется для следующей активной полосы и пропорционально времени, затраченному всеми машинами на преодоление детектируемых участков дороги $R_t = \sum\limits_{\mathmakebox[1em][l]{i \in I(s',t)}} (t -t_i).$

Далее для построенного множества светофорных объектов $TL$  и зон детекции $z$ определяются функция наград $r(s,a)$ число проехавших машин (MCOUNT), суммарное время проезда через детектируемые участки дорожной сети (TIME\_SUMM) и  обучающие функции $Q.$
При симуляции, формируется
двумерная выборка  ${\cal X}=\left\{(s_i, a_i)\right\}_{i=1}^T$
объемом $T$ порядка $10^6$. В результате  управления $\delta^*,$ принятого из соображений увеличения значения функции оценки эффективности $Q,$  рассчитывается  несмещенная оценка
распределения ${\cal P}=\{p(s, a)\}_{s\in{\state}, a\in{\action}}$ двумерной случайной величины $(s, a)$, где функция распределения
$p(s, a)$  --- вероятность того, что в состоянии $s$ агент принял решение $a$.
На основании
выборочных вероятностей  $\hat{p}(s, a)$ вычисляются оценки
политики агента $\hat{\pi}(a| s)$  для каждого $s\in\state$
$$
  \hat{\pi}(a| s)=\frac{\hat{p}(s, a)}{\displaystyle \sum\limits_{a\in{\mathbb A}}\hat{p}(s,a)}=\frac{\hat{p}(s, a)}{\hat{p}(s)}.
$$
%На практике при решении прямой задачи распределение $\perprob\left(s , a\right)$ неизвестно, но т.к. исследуется выборка объемом порядка $10^6$, то по ней возможно восстановить функцию распределения случайной величины. Согласно закону больших чисел
% (ссылка на справочник большакова  
%оно находится с помощью известной  эмпирической функции распределения $\perprob^*_n\left(s , a\right).$
Наряду с политиками агента, при обработке интенсивностей записываются массивы  $r_{a^{(k)}} =\left\{r(s_0,a^{(k)}),r(s_1,a^{(k)}),r(s_2,a^{(k)}),\dots\right\}$, $ k\in K$.
Элементы массивов $r\left(s_t,a^{(k)}\right)$  --- время нахождения машин на активируемых  агентом $k$ и фазой  $a^{(k)}\oplus s_t$  полосах. %Отсчет времени начинается с момента обнаружения машины датчиками.
% Результат обработки интенсивности трафика представлен на рисунке \ref{fig:intens1}.
% \red{добавить рисунок}
% \begin{figure}[H]
%     \centering
%     %\includegraphics[width=0.99\textwidth]{exintens.png}
%     \caption{Интенсивность трафика на перекрестке в течение 24 часов, зеленый цвет соответствует фазе $s^{(0)}$, красный --- $s^{(1)}$}
%     \label{fig:intens1}
% \end{figure}
\label{par:computation}


В ходе серии из 1000 симуляций были построены усредненные кривые обучения  функции оценки эффективности управления $\hat{Q}$  при равновесной по Нэшу стратегии.
Кривые обучения приведенны в таблице~\ref{table:strategies}.

% Результаты вычислительных экспериментов демонстрируют
%  графики кривой обучения $Q^i$ для светофорных объектов $0,1$ при условии ограниченного обзора пространства состояний $\mathcal{O}$ и при условии, когда оно совпадает с полным пространством состояний $\mathbf{\state};$
%  показатели эффективности управления для АСУДД24 и MARLIN24.

% \begin{table}[tbph]\footnotesize
%   \caption{Графики кривых обучения}\label{table:strategies}
%   \centering
%   \begin{tabular}{|p{0.1\textwidth}|l|}\hline
%     \rotatebox[origin = c]{90}{\parbox[s]{0.25\textwidth}{\centering частичный обзор\\$\mathcal{O}\subset \state^0\times\state^1,$                                                                                                                                                   \\ $\mathbf{\state} =  \state^0\times\state^1\times\state^2$}}	& \parbox[s]{0.85\textwidth}{\centering \includegraphics[width = 0.85\textwidth]{learningcurve20.png}\\\includegraphics[width = 0.85\textwidth]{learningcurve21.png}  }\\\hline
%     \rotatebox[origin = c]{90}{\parbox[s]{0.3\textwidth}{\centering  полный обзор\\ \; \\ $\mathcal{O} =  \mathbf{\state} = \state^0\times\state^1\times\state^2$}} & \parbox[s]{0.85\textwidth}{\centering \includegraphics[width = 0.85\textwidth]{learningcurve2.png} } \\\hline
%   \end{tabular}
% \end{table}


% Отметим, что при рассмотрении полного пространства состояний, суммарное время нахождения транспортных на участке, принадлежащем второму светофорному объекту, значительно меньше, чем на $0$ и $1$-ом,  и поэтому в случае полного обзора оно не вносило вклада в изменение  управления. 

В рамках вычислительных экспериментов было проведено сравнение кривых обучения  агентов на протяжении 1000 эпох. 
В результате эффективного управления время ожидания транспортного средства в среднем не превышает длины цикла светофорного объекта. 
Также было продемонстрировано, что значительного улучшения управления при расширении покрытия дорожной сети может и не быть. 
Таким образом, координированное управление светофорными объектами в целях ускорения вычислений может быть рассмотрено только в тех участках, где его применение дает ощутимое улучшение в управлении. 
В остальных случаях может быть рассмотрен некоординированный подход, и, следовательно, <<проклятие размерности>>, возникающее с ростом размерности матриц при вычислениях, не является серьезной проблемой.

\textcolor{red}{Сравнение экспериментов с моделью Anylogic.}

Сравнение комплекса MARLIN24 и АСУДД24 в работе \cite{tislenko2021} показало сопоставимые результаты (таблица~\ref{table:compar1}).
% \begin{table}[tbph]
%   \centering
%   \caption{Сравнение показателей эффективности управления для различных моделей}
%   \label{table:compar1}
%   \scalebox{0.8}{
%     \begin{tabular}{|c|c|>{\columncolor{blue!20}}c |>{\columncolor{red!20}}c |  c|}
%       \hline
%       \parbox[s]{6em}{\rule{0em}{1.2em}Целевая функция}                                                   &
%       \parbox[t]{2em}{Ед.                                                                                   \\ изм.} &
%       \parbox[s]{5em}{\rule{0em}{1.2em}АСУДД24}                                                           &
%       \parbox[s]{5em}{\rule{0em}{1.2em}MARLIN24}                                                          &
%       \rotatebox[origin=B]{90}{\rule{0.2em}{0em}улучшение\rule{0.2em}{0em}}
%       \\
%       \hline
%       \mbox{\parbox[s][1.2\height]{6em}{\rule{0em}{1.5em}Средняя                                            \\ задержка}}&
%       $\frac{\rule[0.2em]{0em}{1.5em}\displaystyle\text{cек.}}{\rule{0em}{1em}\displaystyle\text{маш.}} $ &
%       10.63                                                                                               &
%       9.4                                                                                                 &
%       11.6\%
%       \\
%       \hline
%       \mbox{\parbox[s]{6em}{\rule{0em}{1.5em}Пропускная                                                     \\ способность\rule[-1em]{0em}{1em}}}&
%       маш.                                                                                                &
%       4 870                                                                                               &
%       4 412                                                                                               &
%       -9.4\%
%       \\
%       \hline
%       \mbox{\parbox[s][1.2\height]{6em}{\rule{0em}{1.5em}Суммарное                                          \\ время}}&
%       сек.                                                                                                &
%       51 792                                                                                              &
%       41 286                                                                                              &
%       20.3\%
%       \\
%       \hline
%     \end{tabular}}
% \end{table}
\noindent