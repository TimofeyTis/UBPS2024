
\section{Вычислительные эксперименты}
Для исследования представленных в работе моделей были проведены серии вычислительных экспериментов. Эксперименты проводились на ПК с процессором Intel Core i7-10510U CPU@1.80ГГц и оперативной памятью объемом 8ГБ.

Опишем подробнее процесс подсчета политики управления $\hat{\pi}(a| s),$ опираясь на структурную схему комплекса MARLIN24 на рисунке \ref{fig:structure_MARLIN24}.
Модуль адаптивного управления светофорными объектами загружает управляющий конфигурационный файл trafficLightConfig.xml. В конфигурационном файле содержится информация о возможных направлениях движения, количестве фаз и циклах светофорных объектов.
Далее  комплекс программных средств MARLIN24  связывает  показания  датчика в имитационном модуле  и рассчитывает оптимальное управление для светофорных объектов.

Оптические датчики (VEHICLE DETECTOR) в имитационной среде (SIMULATION)  записывают момент появления $t_i$ пронумерованного транспортного средства $i \in I \subset \mathbb{N}$ в  зоне $z\in Zones  = \left\{z^{(0)}, z^{(1)}, \dots, z^{(m)} \right\}, m \in \mathbb{N}$.
Отметим, что при имитационном моделировании   псевдослучайная интенсивность движения транспортных средств будет задана алгоритмически. Это означает, что мы можем сконструировать множество пар $(i,z),$ что  автомобиль $i$ находится в детектируемой зоне $z$ в момент времени $t.$ Определим данное множество как отношение $\psi_t \subset \mathbb{N} \times Zones, $ для которого  $i\psi_t z.$
Введем также отношение $\phi \subset Zones \times \state,$ описывающее зоны $z, $ в которых состояние $s'$ разрешает движение.
Сгруппируем автомобили в  зонах в соответствии с фазой светофорного объекта $s'$, которая разрешает движение транспортных средств в этих зонах и обозначим
$
  I(s',t) = \left\{i|\;\; t_i < t, i \psi_t z, z \phi s' \right\}.
$

Приведем рассуждения, исходя из которых считается функция вознаграждения.
Для каждой полосы определено число машин  на отрезке дороги, начинающемся с детектора и заканчивающемся стоп-линией перекрестка.
Пусть  $r:  \state \times \action \mapsto \mathbb{R}$ --- функция вознаграждения агента при изменении наблюдаемого состояния $s_t$ при действии $a_t=\delta(s)$. 
В момент времени $t$ значение функции $r(s_t, a_t)=R_t$  определяется для следующей активной полосы и пропорционально времени, затраченному всеми машинами на преодоление детектируемых участков дороги $R_t = \sum\limits_{\mathmakebox[1em][l]{i \in I(s',t)}} (t -t_i).$

Далее для построенного множества светофорных объектов $TL$  и зон детекции $z$ определяются функция наград $r(s,a)$ число проехавших машин (MCOUNT), суммарное время проезда через детектируемые участки дорожной сети (TIME\_SUMM) и  обучающие функции $Q.$
При симуляции, формируется
двумерная выборка  ${\cal X}=\left\{(s_i, a_i)\right\}_{i=1}^T$
объемом $T$ порядка $10^6$. В результате  управления $\delta^*,$ принятого из соображений увеличения значения функции оценки эффективности $Q,$  рассчитывается  несмещенная оценка
распределения ${\cal P}=\{p(s, a)|\; s\in{\state}, a\in{\action}\}$ двумерной случайной величины $(s, a)$, где функция 
$p(s, a)$  --- вероятность того, что в состоянии $s$ агент принял решение $a$.
На основании
выборочных вероятностей  $\hat{p}(s, a)$ вычисляются оценки
политики агента $\hat{\pi}(a| s)$  для каждого $s\in\state$
$$
  \hat{\pi}(a| s)=\frac{\hat{p}(s, a)}{\displaystyle \sum\limits_{a\in{\mathbb A}}\hat{p}(s,a)}=\frac{\hat{p}(s, a)}{\hat{p}(s)}.
$$
%На практике при решении прямой задачи распределение $\perprob\left(s , a\right)$ неизвестно, но т.к. исследуется выборка объемом порядка $10^6$, то по ней возможно восстановить функцию распределения случайной величины. Согласно закону больших чисел
% (ссылка на справочник большакова  
%оно находится с помощью известной  эмпирической функции распределения $\perprob^*_n\left(s , a\right).$
% Наряду с политиками агента, при обработке интенсивностей записываются массивы  $r_{a^{(k)}} =\left\{r(s_0,a^{(k)}),r(s_1,a^{(k)}),r(s_2,a^{(k)}),\dots\right\}$, $ k\in K$.
% Элементы массивов $r\left(s_t,a^{(k)}\right)$  --- время нахождения машин на активируемых  агентом $k$ и фазой  $a^{(k)}\oplus s_t$  полосах. %Отсчет времени начинается с момента обнаружения машины датчиками.
% Результат обработки интенсивности трафика представлен на рисунке \ref{fig:intens1}.
% \red{добавить рисунок}
% \begin{figure}[H]
%     \centering
%     %\includegraphics[width=0.99\textwidth]{exintens.png}
%     \caption{Интенсивность трафика на перекрестке в течение 24 часов, зеленый цвет соответствует фазе $s^{(0)}$, красный --- $s^{(1)}$}
%     \label{fig:intens1}
% \end{figure}
\label{par:computation}

В ходе серии из 1000 симуляций были построены усредненные кривые обучения  функции оценки эффективности управления $\hat{Q}$  при равновесной по Нэшу стратегии \cite{Nash}.
Кривые обучения приведены на рисунке~\ref{fig:strategies}, где синим цветом отмечены графики принимаемых значений $Q$ для каждой эпохи  по модельному времени $t$, красным цветом --- их усредненные значения $\hat{Q}.$
\begin{figure}[tbph]
  \includegraphics[width=0.99\textwidth]{learningcurve40.png}
  \caption{Пример сходимости кривой обучения $Q$  }\label{fig:strategies}
\end{figure}


% Результаты вычислительных экспериментов демонстрируют
%  графики кривой обучения $Q^i$ для светофорных объектов $0,1$ при условии ограниченного обзора пространства состояний $\mathcal{O}$ и при условии, когда оно совпадает с полным пространством состояний $\mathbf{\state};$
%  показатели эффективности управления для АСУДД24 и MARLIN24.

% \begin{table}[tbph]\footnotesize
%   \caption{Графики кривых обучения}\label{table:strategies}
%   \centering
%   \begin{tabular}{|p{0.1\textwidth}|l|}\hline
%     \rotatebox[origin = c]{90}{\parbox[s]{0.25\textwidth}{\centering частичный обзор\\$\mathcal{O}\subset \state^0\times\state^1,$                                                                                                                                                   \\ $\mathbf{\state} =  \state^0\times\state^1\times\state^2$}}	& \parbox[s]{0.85\textwidth}{\centering \includegraphics[width = 0.85\textwidth]{learningcurve20.png}\\\includegraphics[width = 0.85\textwidth]{learningcurve21.png}  }\\\hline
%     \rotatebox[origin = c]{90}{\parbox[s]{0.3\textwidth}{\centering  полный обзор\\ \; \\ $\mathcal{O} =  \mathbf{\state} = \state^0\times\state^1\times\state^2$}} & \parbox[s]{0.85\textwidth}{\centering \includegraphics[width = 0.85\textwidth]{learningcurve2.png} } \\\hline
%   \end{tabular}
% \end{table}


% Отметим, что при рассмотрении полного пространства состояний, суммарное время нахождения транспортных на участке, принадлежащем второму светофорному объекту, значительно меньше, чем на $0$ и $1$-ом,  и поэтому в случае полного обзора оно не вносило вклада в изменение  управления. 

В рамках вычислительных экспериментов было проведено сравнение кривых обучения  агентов на протяжении 1000 эпох. 
В результате эффективного управления время ожидания транспортного средства в среднем не превышает длины цикла светофорного объекта. 
Также было продемонстрировано, что значительного улучшения управления при расширении покрытия дорожной сети может и не быть. 
Таким образом, координированное управление светофорными объектами в целях ускорения вычислений может быть рассмотрено только в тех участках, где его применение дает ощутимое улучшение в управлении. 
В остальных случаях может быть рассмотрен некоординированный подход, и, следовательно, <<проклятие размерности>>, возникающее с ростом размерности матриц при вычислениях, не является серьезной проблемой.

В работе \cite{My2} было проведено сравнение показателей эффективности управления  с комплекса MARLIN24 и АСУДД24.
По результатам эксперимента \cite{My2}, были получены сопоставимые результаты для среднего времени ожидания на участника движения для модели, управляемой марковским процессом принятия решения MARLIN. Данный результат демонстрирует насколько эффективно адаптивные системы светофорных объектов могут быть применены для разгрузки сложных участков дорожной сети.

Также в работе \cite{My3}  было проведено сравнение показателей эффективности управления, рассчитанных для координированного адаптивного управления светофорными объектами  участка дорожной сети (MARLIN), некоординированного адаптивного управления (MARL), для светофорных объектов с фиксированным координационным планом (FIXED) и с переменной длительностью фаз (FUZZY) По результатам эксперимента, было получено качественное отличие  для на $30\%$ для среднего времени ожидания на участника движения для модели, управляемой марковским процессом принятия решения MARLIN.

\section{Заключение}

% \begin{table}[tbph]
%   \centering
%   \caption{Сравнение показателей эффективности управления для различных моделей}
%   \label{table:compar1}
%   \scalebox{0.8}{
%     \begin{tabular}{|c|c|>{\columncolor{blue!20}}c |>{\columncolor{red!20}}c |  c|}
%       \hline
%       \parbox[s]{6em}{\rule{0em}{1.2em}Целевая функция}                                                   &
%       \parbox[t]{2em}{Ед.                                                                                   \\ изм.} &
%       \parbox[s]{5em}{\rule{0em}{1.2em}АСУДД24}                                                           &
%       \parbox[s]{5em}{\rule{0em}{1.2em}MARLIN24}                                                          &
%       \rotatebox[origin=B]{90}{\rule{0.2em}{0em}улучшение\rule{0.2em}{0em}}
%       \\
%       \hline
%       \mbox{\parbox[s][1.2\height]{6em}{\rule{0em}{1.5em}Средняя                                            \\ задержка}}&
%       $\frac{\rule[0.2em]{0em}{1.5em}\displaystyle\text{cек.}}{\rule{0em}{1em}\displaystyle\text{маш.}} $ &
%       10.63                                                                                               &
%       9.4                                                                                                 &
%       11.6\%
%       \\
%       \hline
%       \mbox{\parbox[s]{6em}{\rule{0em}{1.5em}Пропускная                                                     \\ способность\rule[-1em]{0em}{1em}}}&
%       маш.                                                                                                &
%       4 870                                                                                               &
%       4 412                                                                                               &
%       -9.4\%
%       \\
%       \hline
%       \mbox{\parbox[s][1.2\height]{6em}{\rule{0em}{1.5em}Суммарное                                          \\ время}}&
%       сек.                                                                                                &
%       51 792                                                                                              &
%       41 286                                                                                              &
%       20.3\%
%       \\
%       \hline
%     \end{tabular}}
% \end{table}
\noindent